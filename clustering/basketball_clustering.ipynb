{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, Imputer\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "game_stats = pd.read_csv('/Users/beh502/ml-practice/clustering/data/Seasons_Stats.csv')\n",
    "player_stats = pd.read_csv('/Users/beh502/ml-practice/clustering/data/Players.csv')\n",
    "merged_stats = pd.merge(player_stats, game_stats, on='Player', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before cleanup, shape of df is : (24691, 60)\n",
      "before dummy encoding, num features is: 52\n",
      "after dummy encoding, num features is: 53\n"
     ]
    }
   ],
   "source": [
    "print \"before cleanup, shape of df is : \" + str(merged_stats.shape)\n",
    "\n",
    "#some columns are rubbish, some give us no utility\n",
    "merged_stats = merged_stats.drop(['collage','birth_city','birth_state','Tm','Unnamed: 0_x','Unnamed: 0_y','blanl','blank2'], axis=1)\n",
    "merged_stats['player_year'] = merged_stats.Player.map(str) + \"-\" + merged_stats.Year.map(str)\n",
    "merged_stats = merged_stats.drop(['Player'], axis=1) #drop now that we ID by player-year\n",
    "\n",
    "#drop all rows that have some NA values. Only for really old players and they're not elite\n",
    "merged_stats = merged_stats.dropna(axis=0, how='any')\n",
    "\n",
    "#dummy encode 'position' column\n",
    "print \"before dummy encoding, num features is: \" + str(len(list(merged_stats.columns)))\n",
    "merged_stats['Pos'] = merged_stats['Pos'].apply(lambda x: 'Wing' if x in ['SG','PG','SF','G','G-F','SG-PG','SG-SF', 'SF-PG','PG-SG','PG-SF','SF-SG'] else 'Big')\n",
    "merged_stats = pd.get_dummies(merged_stats, prefix=['Pos'], columns=['Pos'])\n",
    "print \"after dummy encoding, num features is: \" + str(len(list(merged_stats.columns)))\n",
    "# added 15 instead of 5 because some players play multiple, ie their value was guard-fwd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = StandardScaler()\n",
    "clusterer = AgglomerativeClustering(n_clusters=100)\n",
    "\n",
    "metrics = merged_stats.drop(['player_year'], axis=1).columns.values\n",
    "merged_stats[metrics] = normalizer.fit_transform(merged_stats[metrics])\n",
    "merged_stats['cluster'] = clusterer.fit_predict(merged_stats[metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 0 count: 310\n",
      "cluster 1 count: 127\n",
      "cluster 2 count: 214\n",
      "cluster 3 count: 50\n",
      "cluster 4 count: 82\n",
      "cluster 5 count: 42\n",
      "cluster 6 count: 92\n",
      "cluster 7 count: 342\n",
      "cluster 8 count: 247\n",
      "cluster 9 count: 181\n",
      "cluster 10 count: 202\n",
      "cluster 11 count: 255\n",
      "cluster 12 count: 303\n",
      "cluster 13 count: 178\n",
      "cluster 14 count: 120\n",
      "cluster 15 count: 64\n",
      "cluster 16 count: 148\n",
      "cluster 17 count: 204\n",
      "cluster 18 count: 167\n",
      "cluster 19 count: 377\n",
      "cluster 20 count: 239\n",
      "cluster 21 count: 385\n",
      "cluster 22 count: 147\n",
      "cluster 23 count: 167\n",
      "cluster 24 count: 346\n",
      "cluster 25 count: 250\n",
      "cluster 26 count: 44\n",
      "cluster 27 count: 78\n",
      "cluster 28 count: 357\n",
      "cluster 29 count: 211\n",
      "cluster 30 count: 178\n",
      "cluster 31 count: 275\n",
      "cluster 32 count: 149\n",
      "cluster 33 count: 86\n",
      "cluster 34 count: 18\n",
      "cluster 35 count: 129\n",
      "cluster 36 count: 149\n",
      "cluster 37 count: 106\n",
      "cluster 38 count: 276\n",
      "cluster 39 count: 155\n",
      "cluster 40 count: 163\n",
      "cluster 41 count: 208\n",
      "cluster 42 count: 118\n",
      "cluster 43 count: 159\n",
      "cluster 44 count: 275\n",
      "cluster 45 count: 39\n",
      "cluster 46 count: 182\n",
      "cluster 47 count: 103\n",
      "cluster 48 count: 111\n",
      "cluster 49 count: 31\n",
      "cluster 50 count: 209\n",
      "cluster 51 count: 223\n",
      "cluster 52 count: 32\n",
      "cluster 53 count: 159\n",
      "cluster 54 count: 136\n",
      "cluster 55 count: 234\n",
      "cluster 56 count: 67\n",
      "cluster 57 count: 195\n",
      "cluster 58 count: 179\n",
      "cluster 59 count: 229\n",
      "cluster 60 count: 143\n",
      "cluster 61 count: 185\n",
      "cluster 62 count: 209\n",
      "cluster 63 count: 75\n",
      "cluster 64 count: 175\n",
      "cluster 65 count: 158\n",
      "cluster 66 count: 122\n",
      "cluster 67 count: 106\n",
      "cluster 68 count: 13\n",
      "cluster 69 count: 156\n",
      "cluster 70 count: 19\n",
      "cluster 71 count: 137\n",
      "cluster 72 count: 65\n",
      "cluster 73 count: 189\n",
      "cluster 74 count: 206\n",
      "cluster 75 count: 114\n",
      "cluster 76 count: 73\n",
      "cluster 77 count: 121\n",
      "cluster 78 count: 109\n",
      "cluster 79 count: 95\n",
      "cluster 80 count: 105\n",
      "cluster 81 count: 76\n",
      "cluster 82 count: 156\n",
      "cluster 83 count: 8\n",
      "cluster 84 count: 119\n",
      "cluster 85 count: 136\n",
      "cluster 86 count: 77\n",
      "cluster 87 count: 17\n",
      "cluster 88 count: 110\n",
      "cluster 89 count: 150\n",
      "cluster 90 count: 53\n",
      "cluster 91 count: 27\n",
      "cluster 92 count: 74\n",
      "cluster 93 count: 30\n",
      "cluster 94 count: 91\n",
      "cluster 95 count: 149\n",
      "cluster 96 count: 8\n",
      "cluster 97 count: 84\n",
      "cluster 98 count: 53\n",
      "cluster 99 count: 90\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,100):\n",
    "    print \"cluster \" + str(i) + \" count: \" + str(len(merged_stats.loc[merged_stats['cluster'] == i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "jordan_93 = merged_stats.loc[merged_stats[\"player_year\"] == \"Michael Jordan*-1993.0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        height    weight     born      Year       Age         G        GS  \\\n",
      "9678 -0.097645 -0.599138 -0.69361 -0.803443  0.538754  0.965643  1.730844   \n",
      "\n",
      "           MP       PER       TS%   ...          AST       STL     BLK  \\\n",
      "9678  1.92949  3.553142  0.810241   ...     2.054015  4.597397  1.0144   \n",
      "\n",
      "           TOV        PF       PTS             player_year   Pos_Big  \\\n",
      "9678  1.872701  0.895794  4.074049  Michael Jordan*-1993.0 -0.695502   \n",
      "\n",
      "      Pos_Wing  cluster  \n",
      "9678  0.695502        6  \n",
      "\n",
      "[1 rows x 54 columns]\n"
     ]
    }
   ],
   "source": [
    "print jordan_95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7482            Magic Johnson*-1987.0\n",
      "7484            Magic Johnson*-1989.0\n",
      "7485            Magic Johnson*-1990.0\n",
      "7486            Magic Johnson*-1991.0\n",
      "9672           Michael Jordan*-1987.0\n",
      "9673           Michael Jordan*-1988.0\n",
      "9674           Michael Jordan*-1989.0\n",
      "9675           Michael Jordan*-1990.0\n",
      "9676           Michael Jordan*-1991.0\n",
      "9677           Michael Jordan*-1992.0\n",
      "9678           Michael Jordan*-1993.0\n",
      "9680           Michael Jordan*-1996.0\n",
      "9681           Michael Jordan*-1997.0\n",
      "9682           Michael Jordan*-1998.0\n",
      "14645               Grant Hill-1996.0\n",
      "14646               Grant Hill-1997.0\n",
      "14647               Grant Hill-1998.0\n",
      "14649               Grant Hill-2000.0\n",
      "15657              Kobe Bryant-2001.0\n",
      "15658              Kobe Bryant-2002.0\n",
      "15659              Kobe Bryant-2003.0\n",
      "15660              Kobe Bryant-2004.0\n",
      "15662              Kobe Bryant-2006.0\n",
      "15663              Kobe Bryant-2007.0\n",
      "15664              Kobe Bryant-2008.0\n",
      "15665              Kobe Bryant-2009.0\n",
      "15666              Kobe Bryant-2010.0\n",
      "15667              Kobe Bryant-2011.0\n",
      "15669              Kobe Bryant-2013.0\n",
      "15837           Allen Iverson*-2000.0\n",
      "                     ...             \n",
      "19682             LeBron James-2015.0\n",
      "19683             LeBron James-2016.0\n",
      "19684             LeBron James-2017.0\n",
      "19909              Dwyane Wade-2005.0\n",
      "19910              Dwyane Wade-2006.0\n",
      "19913              Dwyane Wade-2009.0\n",
      "19914              Dwyane Wade-2010.0\n",
      "19915              Dwyane Wade-2011.0\n",
      "21439              Brandon Roy-2009.0\n",
      "21667             Kevin Durant-2010.0\n",
      "21668             Kevin Durant-2011.0\n",
      "21669             Kevin Durant-2012.0\n",
      "21670             Kevin Durant-2013.0\n",
      "21671             Kevin Durant-2014.0\n",
      "21673             Kevin Durant-2016.0\n",
      "21674             Kevin Durant-2017.0\n",
      "22336             Derrick Rose-2011.0\n",
      "22410        Russell Westbrook-2011.0\n",
      "22412        Russell Westbrook-2013.0\n",
      "22414        Russell Westbrook-2015.0\n",
      "22415        Russell Westbrook-2016.0\n",
      "22416        Russell Westbrook-2017.0\n",
      "22636             James Harden-2015.0\n",
      "22637             James Harden-2016.0\n",
      "22638             James Harden-2017.0\n",
      "23227                John Wall-2017.0\n",
      "23271             Jimmy Butler-2017.0\n",
      "23399            Kawhi Leonard-2016.0\n",
      "23400            Kawhi Leonard-2017.0\n",
      "23943    Giannis Antetokounmpo-2017.0\n",
      "Name: player_year, Length: 92, dtype: object\n"
     ]
    }
   ],
   "source": [
    "top_cluster = merged_stats.loc[merged_stats[\"cluster\"] == 6]\n",
    "print top_cluster['player_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DONE WITH AGGLOMERATIVE CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tsne = TSNE(learning_rate=100).fit_transform(merged_stats[metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_clustering(X_red, X, labels, title=None):\n",
    "    x_min, x_max = np.min(X_red, axis=0), np.max(X_red, axis=0)\n",
    "    X_red = (X_red - x_min) / (x_max - x_min)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    for i in range(X_red.shape[0]):\n",
    "        plt.text(X_red[i, 0], X_red[i, 1], str(y[i]),\n",
    "                 color=plt.cm.spectral(labels[i] / 10.),\n",
    "                 fontdict={'weight': 'bold', 'size': 9})\n",
    "\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if title is not None:\n",
    "        plt.title(title, size=17)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embedding\n",
      "Done.\n",
      "ward : 6.14s\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-831ff8b490c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s : %.2fs\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlinkage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mplot_clustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_red\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclustering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%s linkage\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlinkage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# 2D embedding of the digits dataset\n",
    "print(\"Computing embedding\")\n",
    "X_red = manifold.SpectralEmbedding(n_components=2).fit_transform(merged_stats[metrics])\n",
    "print(\"Done.\")\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "for linkage in ('ward', 'average', 'complete'):\n",
    "    clustering = AgglomerativeClustering(linkage=linkage, n_clusters=10)\n",
    "    t0 = time()\n",
    "    clustering.fit(X_red)\n",
    "    print(\"%s : %.2fs\" % (linkage, time() - t0))\n",
    "\n",
    "    plot_clustering(X_red, X, clustering.labels_, \"%s linkage\" % linkage)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hierarchial (agglomerative)\n",
    "# CURE (compare to hierarchial)\n",
    "# spectral\n",
    "# KNN\n",
    "# SOM (self organizing maps)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
